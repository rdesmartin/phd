
@article{grant_sparse_1996,
	title = {Sparse matrix representations in a functional language},
	volume = {6},
	issn = {1469-7653, 0956-7968},
	url = {https://www.cambridge.org/core/journals/journal-of-functional-programming/article/sparse-matrix-representations-in-a-functional-language/669431E9C12EDC16F02603D833FAC31B},
	doi = {10.1017/S095679680000160X},
	abstract = {This paper investigates several sparse matrix representation schemes and associated algorithms in Haskell for solving linear systems of equations arising from solving realistic computational fluid dynamics problems using a finite element algorithm. This work complements that of Wainwright and Sexton (1992) in that a Choleski direct solver (with an emphasis on its forward/backward substitution steps) is examined. Experimental evidence comparing time and space efficiency of these matrix representation schemes is reported, together with associated forward/backward substitution implementations. Our results are in general agreement with Wainwright and Sexton's.},
	language = {en},
	number = {1},
	urldate = {2022-04-28},
	journal = {Journal of Functional Programming},
	author = {Grant, P. W. and Sharp, J. A. and Webster, M. F. and Zhang, X.},
	month = jan,
	year = {1996},
	note = {Publisher: Cambridge University Press},
	pages = {143--170},
	file = {Full Text PDF:/home/remi/Zotero/storage/R58I8GH7/Grant et al. - 1996 - Sparse matrix representations in a functional lang.pdf:application/pdf;Snapshot:/home/remi/Zotero/storage/AEY5UVNV/669431E9C12EDC16F02603D833FAC31B.html:text/html},
}

@misc{wood_vectors_2019,
	title = {Vectors and {Matrices} in {Agda}},
	url = {https://personal.cis.strath.ac.uk/james.wood.100/blog/html/VecMat.html},
	language = {en-GB},
	urldate = {2022-04-28},
	author = {Wood, James},
	month = aug,
	year = {2019},
}

@inproceedings{heras_incidence_2011,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Incidence {Simplicial} {Matrices} {Formalized} in {Coq}/{SSReflect}},
	isbn = {978-3-642-22673-1},
	doi = {10.1007/978-3-642-22673-1_3},
	abstract = {Simplicial complexes are at the heart of Computational Algebraic Topology, since they give a concrete, combinatorial description of otherwise rather abstract objects which makes many important topological computations possible. The whole theory has many applications such as coding theory, robotics or digital image analysis. In this paper we present a formalization in the Coq theorem prover of simplicial complexes and their incidence matrices as well as the main theorem that gives meaning to the definition of homology groups and is a first step towards their computation.},
	language = {en},
	booktitle = {Intelligent {Computer} {Mathematics}},
	publisher = {Springer},
	author = {Heras, Jónathan and Poza, María and Dénès, Maxime and Rideau, Laurence},
	editor = {Davenport, James H. and Farmer, William M. and Urban, Josef and Rabe, Florian},
	year = {2011},
	keywords = {Chain Complex, Homology Group, Incidence Matrix, Simplicial Complex, Type Object},
	pages = {30--44},
	file = {Full Text PDF:/home/remi/Zotero/storage/PJJ39AA8/Heras et al. - 2011 - Incidence Simplicial Matrices Formalized in CoqSS.pdf:application/pdf},
}

@incollection{kokke_neural_2020,
	address = {Cham},
	title = {Neural {Networks}, {Secure} by {Construction}: {An} {Exploration} of {Refinement} {Types}},
	volume = {12470},
	isbn = {978-3-030-64436-9 978-3-030-64437-6},
	shorttitle = {Neural {Networks}, {Secure} by {Construction}},
	url = {http://link.springer.com/10.1007/978-3-030-64437-6_4},
	abstract = {We present StarChild and Lazuli, two libraries which leverage reﬁnement types to verify neural networks, implemented in F∗ and Liquid Haskell. Reﬁnement types are types augmented, or reﬁned, with assertions about values of that type, e.g., “integers greater than ﬁve”, which are checked by an SMT solver. Crucially, these assertions are written in the language itself. A user of our library can reﬁne the type of neural networks, e.g., “neural networks which are robust against adversarial attacks”, and expect F∗ to handle the veriﬁcation of this claim for any speciﬁc network, without having to change the representation of the network, or even having to learn about SMT solvers.},
	language = {en},
	urldate = {2021-03-30},
	booktitle = {Programming {Languages} and {Systems}},
	publisher = {Springer International Publishing},
	author = {Kokke, Wen and Komendantskaya, Ekaterina and Kienitz, Daniel and Atkey, Robert and Aspinall, David},
	year = {2020},
	doi = {10.1007/978-3-030-64437-6_4},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {67--85},
	file = {Kokke et al. - 2020 - Neural Networks, Secure by Construction An Explor.pdf:/home/remi/Zotero/storage/IAWBCHZB/Kokke et al. - 2020 - Neural Networks, Secure by Construction An Explor.pdf:application/pdf},
}

@article{de_maria_use_2021,
	title = {On the use of formal methods to model and verify neuronal archetypes},
	volume = {16},
	issn = {2095-2236},
	url = {https://doi.org/10.1007/s11704-020-0029-6},
	doi = {10.1007/s11704-020-0029-6},
	abstract = {Having a formal model of neural networks can greatly help in understanding and verifying their properties, behavior, and response to external factors such as disease and medicine. In this paper, we adopt a formal model to represent neurons, some neuronal graphs, and their composition. Some specific neuronal graphs are known for having biologically relevant structures and behaviors and we call them archetypes. These archetypes are supposed to be the basis of typical instances of neuronal information processing. In this paper we study six fundamental archetypes (simple series, series with multiple outputs, parallel composition, negative loop, inhibition of a behavior, and contralateral inhibition), and we consider two ways to couple two archetypes: (i) connecting the output(s) of the first archetype to the input(s) of the second archetype and (ii) nesting the first archetype within the second one. We report and compare two key approaches to the formal modeling and verification of the proposed neuronal archetypes and some selected couplings. The first approach exploits the synchronous programming language Lustre to encode archetypes and their couplings, and to express properties concerning their dynamic behavior. These properties are verified thanks to the use of model checkers. The second approach relies on a theorem prover, the Coq Proof Assistant, to prove dynamic properties of neurons and archetypes.},
	language = {en},
	number = {3},
	urldate = {2022-05-09},
	journal = {Frontiers of Computer Science},
	author = {De Maria, Elisabetta and Bahrami, Abdorrahim and L’Yvonnet, Thibaud and Felty, Amy and Gaffé, Daniel and Ressouche, Annie and Grammont, Franck},
	month = oct,
	year = {2021},
	keywords = {Coq, formal methods, leaky integrate and fire modeling, Lustre, model checking, neuronal networks, synchronous languages, theorem proving},
	pages = {163404},
	file = {Full Text PDF:/home/remi/Zotero/storage/W25VXXCZ/De Maria et al. - 2021 - On the use of formal methods to model and verify n.pdf:application/pdf},
}
