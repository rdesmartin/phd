


@inproceedings{CKDKKAE22,
author = "Marco Casadio and Ekaterina Komendantskaya and Matthew L. Daggitt and Wen Kokke and Guy Katz and Guy Amir and Idan Refaeli",
title = "Neural Network Robustness as a Verification Property: A Principled Case Study",
	series = {Lecture {Notes} in {Computer} {Science}},
	booktitle = {Computer {Aided} {Verification} ({CAV 2022})},
	publisher = {Springer},
	year = "2022"}


@article{grant_sparse_1996,
	title = {Sparse matrix representations in a functional language},
	volume = {6},
	issn = {1469-7653, 0956-7968},
	url = {https://www.cambridge.org/core/journals/journal-of-functional-programming/article/sparse-matrix-representations-in-a-functional-language/669431E9C12EDC16F02603D833FAC31B},
	doi = {10.1017/S095679680000160X},
	abstract = {This paper investigates several sparse matrix representation schemes and associated algorithms in Haskell for solving linear systems of equations arising from solving realistic computational fluid dynamics problems using a finite element algorithm. This work complements that of Wainwright and Sexton (1992) in that a Choleski direct solver (with an emphasis on its forward/backward substitution steps) is examined. Experimental evidence comparing time and space efficiency of these matrix representation schemes is reported, together with associated forward/backward substitution implementations. Our results are in general agreement with Wainwright and Sexton's.},
	language = {en},
	number = {1},
	urldate = {2022-04-28},
	journal = {Journal of Functional Programming},
	author = {Grant, P. W. and Sharp, J. A. and Webster, M. F. and Zhang, X.},
	month = jan,
	year = {1996},
	note = {Publisher: Cambridge University Press},
	pages = {143--170},
	file = {Full Text PDF:/home/remi/Zotero/storage/R58I8GH7/Grant et al. - 1996 - Sparse matrix representations in a functional lang.pdf:application/pdf;Snapshot:/home/remi/Zotero/storage/AEY5UVNV/669431E9C12EDC16F02603D833FAC31B.html:text/html},
}

@misc{wood_vectors_2019,
	title = {Vectors and {Matrices} in {Agda}},
	url = {https://personal.cis.strath.ac.uk/james.wood.100/blog/html/VecMat.html},
	language = {en-GB},
	urldate = {2022-04-28},
	author = {Wood, James},
	month = aug,
	year = {2019},
}

@inproceedings{heras_incidence_2011,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Incidence {Simplicial} {Matrices} {Formalized} in {Coq}/{SSReflect}},
	isbn = {978-3-642-22673-1},
	doi = {10.1007/978-3-642-22673-1_3},
	abstract = {Simplicial complexes are at the heart of Computational Algebraic Topology, since they give a concrete, combinatorial description of otherwise rather abstract objects which makes many important topological computations possible. The whole theory has many applications such as coding theory, robotics or digital image analysis. In this paper we present a formalization in the Coq theorem prover of simplicial complexes and their incidence matrices as well as the main theorem that gives meaning to the definition of homology groups and is a first step towards their computation.},
	language = {en},
	booktitle = {Intelligent {Computer} {Mathematics}},
	publisher = {Springer},
	author = {Heras, Jónathan and Poza, María and Dénès, Maxime and Rideau, Laurence},
	editor = {Davenport, James H. and Farmer, William M. and Urban, Josef and Rabe, Florian},
	year = {2011},
	keywords = {Chain Complex, Homology Group, Incidence Matrix, Simplicial Complex, Type Object},
	pages = {30--44},
	file = {Full Text PDF:/home/remi/Zotero/storage/PJJ39AA8/Heras et al. - 2011 - Incidence Simplicial Matrices Formalized in CoqSS.pdf:application/pdf},
}

@incollection{kokke_neural_2020,
	address = {Cham},
	title = {Neural {Networks}, {Secure} by {Construction}: {An} {Exploration} of {Refinement} {Types}},
	volume = {12470},
	isbn = {978-3-030-64436-9 978-3-030-64437-6},
	shorttitle = {Neural {Networks}, {Secure} by {Construction}},
	url = {http://link.springer.com/10.1007/978-3-030-64437-6_4},
	abstract = {We present StarChild and Lazuli, two libraries which leverage reﬁnement types to verify neural networks, implemented in F∗ and Liquid Haskell. Reﬁnement types are types augmented, or reﬁned, with assertions about values of that type, e.g., “integers greater than ﬁve”, which are checked by an SMT solver. Crucially, these assertions are written in the language itself. A user of our library can reﬁne the type of neural networks, e.g., “neural networks which are robust against adversarial attacks”, and expect F∗ to handle the veriﬁcation of this claim for any speciﬁc network, without having to change the representation of the network, or even having to learn about SMT solvers.},
	language = {en},
	urldate = {2021-03-30},
	booktitle = {Programming {Languages} and {Systems}},
	publisher = {Springer International Publishing},
	author = {Kokke, Wen and Komendantskaya, Ekaterina and Kienitz, Daniel and Atkey, Robert and Aspinall, David},
	year = {2020},
	doi = {10.1007/978-3-030-64437-6_4},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {67--85},
	file = {Kokke et al. - 2020 - Neural Networks, Secure by Construction An Explor.pdf:/home/remi/Zotero/storage/IAWBCHZB/Kokke et al. - 2020 - Neural Networks, Secure by Construction An Explor.pdf:application/pdf},
}

@article{de_maria_use_2021,
	title = {On the use of formal methods to model and verify neuronal archetypes},
	volume = {16},
	issn = {2095-2236},
	url = {https://doi.org/10.1007/s11704-020-0029-6},
	doi = {10.1007/s11704-020-0029-6},
	abstract = {Having a formal model of neural networks can greatly help in understanding and verifying their properties, behavior, and response to external factors such as disease and medicine. In this paper, we adopt a formal model to represent neurons, some neuronal graphs, and their composition. Some specific neuronal graphs are known for having biologically relevant structures and behaviors and we call them archetypes. These archetypes are supposed to be the basis of typical instances of neuronal information processing. In this paper we study six fundamental archetypes (simple series, series with multiple outputs, parallel composition, negative loop, inhibition of a behavior, and contralateral inhibition), and we consider two ways to couple two archetypes: (i) connecting the output(s) of the first archetype to the input(s) of the second archetype and (ii) nesting the first archetype within the second one. We report and compare two key approaches to the formal modeling and verification of the proposed neuronal archetypes and some selected couplings. The first approach exploits the synchronous programming language Lustre to encode archetypes and their couplings, and to express properties concerning their dynamic behavior. These properties are verified thanks to the use of model checkers. The second approach relies on a theorem prover, the Coq Proof Assistant, to prove dynamic properties of neurons and archetypes.},
	language = {en},
	number = {3},
	urldate = {2022-05-09},
	journal = {Frontiers of Computer Science},
	author = {De Maria, Elisabetta and Bahrami, Abdorrahim and L’Yvonnet, Thibaud and Felty, Amy and Gaffé, Daniel and Ressouche, Annie and Grammont, Franck},
	month = oct,
	year = {2021},
	keywords = {Coq, formal methods, leaky integrate and fire modeling, Lustre, model checking, neuronal networks, synchronous languages, theorem proving},
	pages = {163404},
	file = {Full Text PDF:/home/remi/Zotero/storage/W25VXXCZ/De Maria et al. - 2021 - On the use of formal methods to model and verify n.pdf:application/pdf},
}
%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Tgl at 2021-10-04 16:35:24 +0100 


%% Saved with string encoding Unicode (UTF-8)



@inproceedings{DKAAK22,
title = "Vehicle: Interfacing Neural Network Verifiers with
Interactive Theorem Provers",
author = "Matthew Daggitt and Wen Kokke and Robert Atkey and Luca Arnaboldi and Ekaterina Komendantskaya",
booktitle = "Submitted to ITP'22",
year = "2022"}


@article{boyer-moore-linear-arithmetic,
  title={Integrating decision procedures into heuristic theorem provers: a case study of linear arithmetic},
  author={Robert S. Boyer and J Strother Moore},
  journal={Machine intelligence},
  year={1988},
  pages={83-124}
}


@inproceedings{demoura-passmore-real-closed-extensions,
  title={Computation in Real Closed Infinitesimal and Transcendental Extensions of the Rationals},
  author={Leonardo de Moura and Grant Olney Passmore},
  booktitle={CADE},
  year={2013}
}


@inproceedings{JiaR21,
  author    = {Kai Jia and
               Martin Rinard},
  title     = {Exploiting Verified Neural Networks via Floating Point Numerical Error},
  booktitle = {Static Analysis - 28th International Symposium, {SAS} 2021, Chicago,
               IL, USA, October 17-19, 2021, Proceedings},
  pages     = {191--205},
  year      = {2021},
  series    = {Lecture Notes in Computer Science},
  volume    = {12913},
  publisher = {Springer}}

@inproceedings{TassarottiV0T21,
  author    = {Joseph Tassarotti and
               Koundinya Vajjha and
               Anindya Banerjee and
               Jean{-}Baptiste Tristan},
  title     = {A formal proof of {PAC} learnability for decision stumps},
  booktitle = {{CPP} '21: 10th {ACM} {SIGPLAN} International Conference on Certified
               Programs and Proofs, Virtual Event, Denmark, January 17-19, 2021},
  pages     = {5--17},
  year      = {2021},
  publisher = {{ACM}}}

@inproceedings{LundbergL17,
  author    = {Scott M. Lundberg and
               Su{-}In Lee},
  title     = {A Unified Approach to Interpreting Model Predictions},
  booktitle = {Advances in Neural Information Processing Systems 30: Annual Conference
               on Neural Information Processing Systems (NIPS) 2017, December 4-9, 2017,
               Long Beach, CA, {USA}},
  pages     = {4765--4774},
  year      = {2017}}

@inproceedings{Ribeiro0G16,
  author    = {Marco T{\'{u}}lio Ribeiro and
               Sameer Singh and
               Carlos Guestrin},
  title     = {"Why Should {I} Trust You?": Explaining the Predictions of Any Classifier},
  booktitle = {Proceedings of the 22nd {ACM} {SIGKDD} International Conference on
               Knowledge Discovery and Data Mining, San Francisco, CA, USA, August
               13-17, 2016},
  pages     = {1135--1144},
  year      = {2016},
  publisher = {{ACM}}}

@inproceedings{MazzucatoU21,
  author    = {Denis Mazzucato and
               Caterina Urban},
  title     = {Reduced Products of Abstract Domains for Fairness Certification of
               Neural Networks},
  booktitle = {Static Analysis - 28th International Symposium, {SAS} 2021, Chicago,
               IL, USA, October 17-19, 2021, Proceedings},
  pages     = {308--322},
  year      = {2021},
  series    = {Lecture Notes in Computer Science},
  volume    = {12913},
  publisher = {Springer}}

@article{UrbanCWZ20,
  author    = {Caterina Urban and
               Maria Christakis and
               Valentin W{\"{u}}stholz and
               Fuyuan Zhang},
  title     = {Perfectly parallel fairness certification of neural networks},
  journal   = {Proc. {ACM} Program. Lang.},
  volume    = {4},
  number    = {{OOPSLA}},
  pages     = {185:1--185:30},
  year      = {2020}}

@book{JS98,
author = "Joseph Sill",
title = "Monotonic Networks",
publisher = "California Institute of Technology",
year = "1998"}


@inproceedings{WehenkelL19,
  author    = {Antoine Wehenkel and
               Gilles Louppe},
  title     = {Unconstrained Monotonic Neural Networks},
  booktitle = {Advances in Neural Information Processing Systems 32: Annual Conference
               on Neural Information Processing Systems 2019, NeurIPS 2019, December
               8-14, 2019, Vancouver, BC, Canada},
  pages     = {1543--1553},
  year      = {2019}
}

@inproceedings{HuangKWW17,
  author    = {Xiaowei Huang and
               Marta Kwiatkowska and
               Sen Wang and
               Min Wu},
  title     = {Safety Verification of Deep Neural Networks},
  booktitle = {Computer Aided Verification - 29th International Conference, {CAV}
               2017, Heidelberg, Germany, July 24-28, 2017, Proceedings, Part {I}},
  pages     = {3--29},
  year      = {2017},
  series    = {Lecture Notes in Computer Science},
  volume    = {10426}}

@inproceedings{PassmoreCIABKKM20,
  author    = {Grant O. Passmore and
               Simon Cruanes and
               Denis Ignatovich and
               Dave Aitken and
               Matt Bray and
               Elijah Kagan and
               Kostya Kanishev and
               Ewen Maclean and
               Nicola Mometto},
  title     = {The Imandra Automated Reasoning System (System Description)},
  booktitle = {Automated Reasoning - 10th International Joint Conference, {IJCAR}
               2020, Paris, France, July 1-4, 2020, Proceedings, Part {II}},
  pages     = {464--471},
  year      = {2020},
    volume    = {12167},
  publisher = {Springer},
  biburl    = {https://dblp.org/rec/conf/cade/PassmoreCIABKKM20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{PF18,
  author    = {Petros Papapanagiotou and
               Jacques D. Fleuriot},
  title     = {The Boyer-Moore Waterfall Model Revisited},
  journal   = {CoRR},
  volume    = {abs/1808.03810},
  year      = {2018},
  url       = {http://arxiv.org/abs/1808.03810},
  eprinttype = {arXiv},
  eprint    = {1808.03810},
  timestamp = {Sun, 02 Sep 2018 15:01:57 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1808-03810.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@book{BM79,
author = "Robert S. Boyer and J Strother Moore ",
title = "A Computational Logic",
publisher = "ACM Monograph Series. Academic Press, New York",
year = "1979"}

@misc{DPKD22,
	author = {Remi Desmartin and Grant Passmore and Ekaterina Komendantskaya and Matthew L. Daggitt},
	howpublished = {\url{https://github.com/aisec-private/ImandraNN}},
	journal = {GitHub repository},
	publisher = {GitHub},
	title = {{CNN} Library in {I}mandra},
	year = {2022}}


@article{MariaBLFGRG22,
  author    = {Elisabetta De Maria and
               Abdorrahim Bahrami and
               Thibaud L'Yvonnet and
               Amy P. Felty and
               Daniel Gaff{\'{e}} and
               Annie Ressouche and
               Franck Grammont},
  title     = {On the use of formal methods to model and verify neuronal archetypes},
  journal   = {Frontiers Comput. Sci.},
  volume    = {16},
  number    = {3},
  pages     = {163404},
  year      = {2022}
}

@inproceedings{KokkeKKAA20,
  author    = {Wen Kokke and
               Ekaterina Komendantskaya and
               Daniel Kienitz and
               Robert Atkey and
               David Aspinall},
  title     = {Neural Networks, Secure by Construction - An Exploration of Refinement
               Types},
  booktitle = {Programming Languages and Systems - 18th Asian Symposium, {APLAS}
               2020, Fukuoka, Japan, November 30 - December 2, 2020, Proceedings},
  pages     = {67--85},
  year      = {2020},
  series    = {Lecture Notes in Computer Science},
  volume    = {12470},
  publisher = {Springer}
}


@inproceedings{TassarottiV0T21,
  author    = {Joseph Tassarotti and
               Koundinya Vajjha and
               Anindya Banerjee and
               Jean{-}Baptiste Tristan},
  title     = {A formal proof of {PAC} learnability for decision stumps},
  booktitle = {{CPP} '21: 10th {ACM} {SIGPLAN} International Conference on Certified
               Programs and Proofs, Virtual Event, Denmark, January 17-19, 2021},
  pages     = {5--17},
  year      = {2021},
  publisher = {ACM}
}

@inproceedings{Passmore21,
  author    = {Grant Olney Passmore},
  title     = {Some Lessons Learned in the Industrialization of Formal Methods for
               Financial Algorithms},
  booktitle = {Formal Methods - 24th International Symposium, {FM} 2021, Virtual
               Event, November 20-26, 2021, Proceedings},
  pages     = {717--721},
  year      = {2021},
  series    = {Lecture Notes in Computer Science},
  volume    = {13047},
  publisher = {Springer}}

@misc{CDKK21,
	author = {Marco Casadio and Matthew L. Daggitt and Daniel Kienitz and Wen Kokke},
	howpublished = {\url{https://github.com/aisec-private/training-with-constraints}},
	journal = {GitHub repository},
	publisher = {GitHub},
	title = {Property-driven Training: All You (N)Ever Wanted to Know About},
	year = {2021}}

@article{ShortenK19,
	author = {Connor Shorten and Taghi M. Khoshgoftaar},
	journal = {J. Big Data},
	pages = {60},
	title = {A survey on Image Data Augmentation for Deep Learning},
	volume = {6},
	year = {2019}}

@inproceedings{BalunovicV20,
	author = {Mislav Balunovic and Martin T. Vechev},
	booktitle = {8th International Conference on Learning Representations, {ICLR} 2020, Addis Ababa, Ethiopia, April 26-30, 2020},
	publisher = {OpenReview.net},
	title = {Adversarial Training and Provable Defenses: Bridging the Gap},
	year = {2020}}

@inproceedings{resnet,
	author = {K. {He} and X. {Zhang} and S. {Ren} and J. {Sun}},
	booktitle = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	doi = {10.1109/CVPR.2016.90},
	pages = {770-778},
	title = {Deep Residual Learning for Image Recognition},
	year = {2016},
	Bdsk-Url-1 = {https://doi.org/10.1109/CVPR.2016.90}}

@misc{fashionmnist,
	archiveprefix = {arXiv},
	author = {Han Xiao and Kashif Rasul and Roland Vollgraf},
	eprint = {1708.07747},
	primaryclass = {cs.LG},
	title = {Fashion-{MNIST}: a Novel Image Dataset for Benchmarking Machine Learning Algorithms},
	year = {2017}}

@inproceedings{gtsrb,
	author = {Johannes Stallkamp and Marc Schlipsing and Jan Salmen and Christian Igel},
	booktitle = {IEEE International Joint Conference on Neural Networks},
	pages = {1453--1460},
	title = {The {G}erman {T}raffic {S}ign {R}ecognition {B}enchmark: A multi-class classification competition},
	year = {2011}}

@article{cifar10,
	author = {Krizhevsky and Alex},
	journal = {University of Toronto},
	month = {05},
	title = {Learning Multiple Layers of Features from Tiny Images},
	year = {2012}}

@inproceedings{GoodfellowSS14,
	author = {Ian J. Goodfellow and Jonathon Shlens and Christian Szegedy},
	booktitle = {3rd International Conference on Learning Representations, {ICLR} 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
	editor = {Yoshua Bengio and Yann LeCun},
	title = {Explaining and Harnessing Adversarial Examples},
	year = {2015}}

@inproceedings{XuZFLB18,
	author = {Jingyi Xu and Zilu Zhang and Tal Friedman and Yitao Liang and Guy Van den Broeck},
	booktitle = {Proceedings of the 35th International Conference on Machine Learning, {ICML} 2018, Stockholmsm{\"{a}}ssan, Stockholm, Sweden, July 10-15, 2018},
	editor = {Jennifer G. Dy and Andreas Krause},
	pages = {5498--5507},
	publisher = {{PMLR}},
	series = {Proceedings of Machine Learning Research},
	title = {A Semantic Loss Function for Deep Learning with Symbolic Knowledge},
	volume = {80},
	year = {2018}}

@inproceedings{KKK20,
	author = {Ekaterina Komendantskaya and Wen Kokke and Daniel Kienitz},
	booktitle = {{PPDP} '20: 22nd International Symposium on Principles and Practice of Declarative Programming, Bologna, Italy, 9-10 September, 2020},
	pages = {1:1--1:3},
	publisher = {{ACM}},
	title = {Continuous Verification of Machine Learning: a Declarative Programming Approach},
	year = {2020}}

@inproceedings{AEHW20,
	author = {Edward W. Ayers and Francisco Eiras and Majd Hawasly and Iain Whiteside},
	booktitle = {{NASA} Formal Methods - 12th International Symposium, {NFM} 2020, Moffett Field, CA, USA, May 11-15, 2020, Proceedings},
	pages = {63--84},
	publisher = {Springer},
	series = {LNCS},
	title = {{P}a{R}o{T}: {A} Practical Framework for Robust Deep Neural Network Training},
	volume = {12229},
	year = {2020}}

@inproceedings{intriguing_properties_of_neural_networks_2014_szegedy,
	author = {Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
	booktitle = {2nd International Conference on Learning Representations, ICLR 2014},
	title = {Intriguing properties of neural networks},
	year = {2014}}

@inproceedings{PapernotMSH16,
	author = {Nicolas Papernot and Patrick D. McDaniel and Ananthram Swami and Richard E. Harang},
	booktitle = {2016 {IEEE} Military Communications Conference, {MILCOM} 2016, Baltimore, MD, USA, November 1-3, 2016},
	editor = {Jerry Brand and Matthew C. Valenti and Akinwale Akinpelu and Bharat T. Doshi and Bonnie L. Gorsic},
	pages = {49--54},
	publisher = {{IEEE}},
	title = {Crafting adversarial input sequences for recurrent neural networks},
	year = {2016}}

@article{SP18,
	author = {Alexandru Constantin Serban and Erik Poll},
	journal = {CoRR},
	title = {Adversarial Examples - {A} Complete Characterisation of the Phenomenon},
	url = {http://arxiv.org/abs/1810.01185},
	volume = {abs/1810.01185},
	year = {2018},
	Bdsk-Url-1 = {http://arxiv.org/abs/1810.01185}}

@article{lecun2010mnist,
	author = {LeCun, Yann and Cortes, Corinna and Burges, CJ},
	journal = {ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},
	title = {{MNIST} handwritten digit database},
	volume = {2},
	year = {2010}}

@article{FLR17,
	author = {K.~Fisher and John Launchbury and Raymond Richards},
	journal = {Phil. Trans. Royal Society},
	title = {The {HACMS} program: using formal methods to eliminate exploitable bugs},
	year = {2017}}

@inproceedings{HuangKWW17,
	author = {Xiaowei Huang and Marta Kwiatkowska and Sen Wang and Min Wu},
	booktitle = {CAV 2017},
	pages = {3--29},
	publisher = {Springer},
	title = {Safety Verification of Deep Neural Networks},
	volume = {LNCS 10426},
	year = {2017}}

@inproceedings{KatzHIJLLSTWZDK19,
	author = {Guy Katz and Derek A. Huang and Duligur Ibeling and Kyle Julian and Christopher Lazarus and Rachel Lim and Parth Shah and Shantanu Thakoor and Haoze Wu and Aleksandar Zeljic and David L. Dill and Mykel J. Kochenderfer and Clark W. Barrett},
	booktitle = {{CAV} 2019, Part {I}},
	pages = {443--452},
	publisher = {Springer},
	series = {LNCS},
	title = {The {Marabou} Framework for Verification and Analysis of Deep Neural Networks},
	volume = {11561},
	year = {2019}}

@inproceedings{swamy2016,
	author = {Nikhil Swamy and Markulf Kohlweiss and Jean-Karim Zinzindohoue and Santiago Zanella-B{\'{e}}guelin and C{\u{a}}t{\u{a}}lin Hri{\c{t}}cu and Chantal Keller and Aseem Rastogi and Antoine Delignat-Lavaud and Simon Forest and Karthikeyan Bhargavan and C{\'{e}}dric Fournet and Pierre-Yves Strub},
	booktitle = {Proceedings of the 43rd Annual {ACM} {SIGPLAN}-{SIGACT} Symposium on Principles of Programming Languages - {POPL} 2016},
	publisher = {{ACM} Press},
	title = {Dependent types and multi-monadic effects in \fstar},
	year = {2016}}

@phdthesis{vazou2016,
	author = {Niki Vazou},
	school = {University of California, San Diego, {USA}},
	title = {Liquid Haskell: Haskell as a Theorem Prover},
	year = {2016}}

@article{McP43,
	author = {W.S. McCulloch and W. Pitts},
	journal = {Bulletin of Math. Bio.},
	pages = {115-133},
	title = {A logical calculus of the ideas immanent in nervous activity},
	volume = {5},
	year = {1943}}

@inproceedings{barrett2010smt,
	author = {Barrett, Clark and Stump, Aaron and Tinelli, Cesare and others},
	booktitle = {Proceedings of the 8th international workshop on satisfiability modulo theories (Edinburgh, England)},
	pages = {14},
	title = {The smt-lib standard: Version 2.0},
	volume = {13},
	year = {2010}}

@misc{chollet2015keras,
	author = {Chollet, Fran\c{c}ois and others},
	howpublished = {{https://keras.io}},
	title = {Keras},
	year = {2015}}

@article{vazou2018,
	author = {Niki Vazou and Anish Tondwalkar and Vikraman Choudhury and Ryan G. Scott and Ryan R. Newton and Philip Wadler and Ranjit Jhala},
	journal = {Proceedings of the {ACM} on Programming Languages},
	month = jan,
	number = {{POPL}},
	pages = {1--31},
	publisher = {Association for Computing Machinery ({ACM})},
	title = {Refinement reflection: complete verification with {SMT}},
	volume = {2},
	year = {2018}}

@inproceedings{MouraB08,
	author = {Leonardo Mendon{\c{c}}a de Moura and Nikolaj Bj{\o}rner},
	booktitle = {TACAS'08},
	pages = {337--340},
	series = {LNCS},
	title = {{Z3:} An Efficient {SMT} Solver},
	volume = {4963},
	year = {2008}}

@incollection{Dutertre2006,
	author = {Bruno Dutertre and Leonardo de Moura},
	booktitle = {Computer Aided Verification},
	pages = {81--94},
	publisher = {Springer Berlin Heidelberg},
	title = {A Fast Linear-Arithmetic Solver for {DPLL}(T)},
	year = {2006}}

@article{Jovanovi2013,
	author = {Dejan Jovanovi{\'{c}} and Leonardo de Moura},
	journal = {{ACM} Communications in Computer Algebra},
	month = jan,
	number = {3/4},
	pages = {104},
	publisher = {Association for Computing Machinery ({ACM})},
	title = {Solving non-linear arithmetic},
	volume = {46},
	year = {2013}}

@article{Akbarpour2009,
	author = {Behzad Akbarpour and Lawrence Charles Paulson},
	journal = {Journal of Automated Reasoning},
	month = aug,
	number = {3},
	pages = {175--205},
	publisher = {Springer Science and Business Media {LLC}},
	title = {{MetiTarski}: An Automatic Theorem Prover for Real-Valued Special Functions},
	volume = {44},
	year = {2009}}

@article{BS19,
	author = {Alexander Bagnall and
               Gordon Stewart},
	journal = {AAAI},
	title = {Certifying True Error: Machine Learning in {Coq} with Verified Generalisation Guarantees},
	year = {2019}}

@inproceedings{WoodcockC00Y19,
	author = {Jim Woodcock and Ana Cavalcanti and Simon Foster and Alexandre Mota and Kangfeng Ye},
	booktitle = {{UTP} 2019},
	pages = {80--105},
	title = {{Probabilistic Semantics for RoboChart - {A} Weakest Completion Approach}},
	year = {2019}}

@inproceedings{Kwiatkowska19,
	author = {Marta Z. Kwiatkowska},
	booktitle = {{CONCUR} 2019,},
	editor = {Wan Fokkink and Rob van Glabbeek},
	pages = {1:1--1:5},
	publisher = {Schloss Dagstuhl - Leibniz-Zentrum f{\"{u}}r Informatik},
	series = {LIPIcs},
	title = {Safety Verification for Deep Neural Networks with Provable Guarantees (Invited Paper)},
	volume = {140},
	year = {2019}}

@inproceedings{DBLP:conf/fpga/UmurogluFGBLJV17,
	author = {Yaman Umuroglu and Nicholas J. Fraser and Giulio Gambardella and Michaela Blott and Philip Heng Wai Leong and Magnus Jahre and Kees A. Vissers},
	booktitle = {Proceedings of the 2017 {ACM/SIGDA} International Symposium on Field-Programmable Gate Arrays, {FPGA} 2017, Monterey, CA, USA, February 22-24, 2017},
	pages = {65--74},
	title = {{FINN:} {A} Framework for Fast, Scalable Binarized Neural Network Inference},
	year = {2017}}

@misc{tensorflow2015-whitepaper,
	author = {Mart\'{\i}n Abadi and Ashish Agarwal and Paul Barham and Eugene Brevdo and Zhifeng Chen and Craig Citro and Greg S. Corrado and Andy Davis and Jeffrey Dean and Matthieu Devin and Sanjay Ghemawat and Ian Goodfellow and Andrew Harp and Geoffrey Irving and Michael Isard and Yangqing Jia and Rafal Jozefowicz and Lukasz Kaiser and Manjunath Kudlur and Josh Levenberg and Dan Mane and Rajat Monga and Sherry Moore and Derek Murray and Chris Olah and Mike Schuster and Jonathon Shlens and Benoit Steiner and Ilya Sutskever and Kunal Talwar and Paul Tucker and Vincent Vanhoucke and Vijay Vasudevan and Fernanda Viegas and Oriol Vinyals and Pete Warden and Martin Wattenberg and Martin Wicke and Yuan Yu and Xiaoqiang Zheng},
	title = {{TensorFlow}: Large-Scale Machine Learning on Heterogeneous Distributed Systems},
	year = {2016}}

@inproceedings{FischerBDGZV19,
	author = {Marc Fischer and Mislav Balunovic and Dana Drachsler{-}Cohen and Timon Gehr and Ce Zhang and Martin T. Vechev},
	booktitle = {Proc. of the 36th Int. Conf. Machine Learning, {ICML} 2019},
	pages = {1931--1941},
	publisher = {{PMLR}},
	title = {{DL2:} Training and Querying Neural Networks with Logic},
	volume = {97},
	year = {2019}}

@techreport{learning_multiple_layers_of_features_from_tiny_images_2009_Krizhevsky,
	author = {Krizhevsky, Alex and Hinton, Geoffrey and others},
	institution = {Citeseer},
	title = {Learning multiple layers of features from tiny images},
	year = {2009}}

@inproceedings{handwritten_digit_recognition_with_a_back_propagation_network_1990_lecun,
	author = {LeCun, Yann and Boser, Bernhard E and Denker, John S and Henderson, Donnie and Howard, Richard E and Hubbard, Wayne E and Jackel, Lawrence D},
	booktitle = {Advances in neural information processing systems},
	pages = {396--404},
	title = {Handwritten digit recognition with a back-propagation network},
	year = {1990}}

@techreport{learning_multiple_layers_of_features_from_tiny_images_2009_Krizhevsky,
	author = {Krizhevsky, Alex and Hinton, Geoffrey and others},
	institution = {Citeseer},
	title = {Learning multiple layers of features from tiny images},
	year = {2009}}

@inproceedings{adam_A_method_for_stochastic_optimization_2017_kingma,
	author = {Kingma, Diederik P and Ba, Jimmy},
	booktitle = {ICLR (Poster)},
	title = {Adam: A Method for Stochastic Optimization},
	year = {2015}}

@article{towards_deep_neural_network_architectures_robust_to_adversarial_examples_2015_gu,
	author = {Gu, Shixiang and Rigazio, Luca},
	journal = {arXiv preprint arXiv:1412.5068},
	title = {Towards deep neural network architectures robust to adversarial examples},
	year = {2014}}

@inproceedings{ZhaoBSRF0020,
	author = {Xingyu Zhao and Alec Banks and James Sharp and Valentin Robu and David Flynn and Michael Fisher and Xiaowei Huang},
	booktitle = {SAFECOMP},
	title = {A Safety Framework for Critical Systems Utilising Deep Neural Networks},
	year = {2020}}

@inproceedings{Katz-rec,
	author = {Yuval Jacoby and Clark W. Barrett and Guy Katz},
	booktitle = {ATVA},
	title = {Verifying Recurrent Neural Networks using Invariant Inference},
	year = {2020}}

@inproceedings{HumptyDumpty2020,
	author = {R. {Schuster} and T. {Schuster} and Y. {Meri} and V. {Shmatikov}},
	booktitle = {S\&P},
	title = {Humpty Dumpty: Controlling Word Meanings via Corpus Poisoning},
	year = {2020}}

@article{GPT-3,
	author = {Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
	journal = {arXiv preprint arXiv:2005.14165},
	title = {Language models are few-shot learners},
	year = {2020}}

@inproceedings{poisonedLMs:ACL2020,
	author = {Kurita, Keita and Michel, Paul and Neubig, Graham},
	booktitle = {ACL},
	title = {Weight Poisoning Attacks on Pretrained Models},
	year = {2020}}

@inproceedings{textdegeneration,
	author = {Holtzman, Ari and Buys, Jan and Du, Li and Forbes, Maxwell and Choi, Yejin},
	booktitle = {International Conference on Learning Representations},
	title = {The Curious Case of Neural Text Degeneration},
	year = {2019}}

@inproceedings{vijayaraghavan2019generating,
	author = {Vijayaraghavan, Prashanth and Roy, Deb},
	booktitle = {Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
	organization = {Springer},
	pages = {711--726},
	title = {Generating Black-Box Adversarial Examples for Text Classifiers Using a Deep Reinforced Model},
	year = {2019}}

@article{wang2019advcodec,
	author = {Wang, Boxin and Pei, Hengzhi and Liu, Han and Li, Bo},
	journal = {arXiv preprint arXiv:1912.10375},
	title = {AdvCodec: Towards A Unified Framework for Adversarial Text Generation},
	year = {2019}}

@inproceedings{bert,
	abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7{\%} (4.6{\%} absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
	address = {Minneapolis, Minnesota},
	author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
	doi = {10.18653/v1/N19-1423},
	month = jun,
	pages = {4171--4186},
	publisher = {Association for Computational Linguistics},
	title = {{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding},
	url = {https://www.aclweb.org/anthology/N19-1423},
	year = {2019},
	Bdsk-Url-1 = {https://www.aclweb.org/anthology/N19-1423},
	Bdsk-Url-2 = {https://doi.org/10.18653/v1/N19-1423}}

@inproceedings{transformers,
	author = {Vaswani, Ashish and others},
	booktitle = {NIPS},
	title = {Attention is All you Need},
	year = {2017}}

@inproceedings{sixteenheads:2019,
	author = {Michel, Paul and Levy, Omer and Neubig, Graham},
	booktitle = {NeurIPS},
	title = {Are Sixteen Heads Really Better than One?},
	year = {2019}}

@inproceedings{HKP20,
	author = {Alasdair Hill and Ekaterina Komendantskaya and Ronald PA Petrick},
	booktitle = {PPDP'20},
	title = {Proof-Carrying Plans: a Resource Logic for {AI} Planning},
	year = {2020}}

@inproceedings{SchwaabKHFPWH19,
	author = {Christopher Schwaab and Ekaterina Komendantskaya and Alasdair Hill and Frantisek Farka and Ronald PA Petrick and Joe B. Wells and Kevin Hammond},
	booktitle = {PADL20},
	title = {Proof-Carrying Plans},
	year = {2019}}

@inproceedings{ElGoKa20,
	author = {Elboher, Y. and Gottschlich, J. and Katz, G.},
	booktitle = {Proc. 32nd Int. Conf. on Computer Aided Verification (CAV)},
	pages = {43--65},
	title = {{An Abstraction-Based Framework for Neural Network Verification}},
	year = {2020}}

@article{SinghGPV19,
	author = {Gagandeep Singh and Timon Gehr and Markus P{\"{u}}schel and Martin T. Vechev},
	doi = {10.1145/3290354},
	journal = {{PACMPL}},
	number = {{POPL}},
	pages = {41:1--41:30},
	title = {An abstract domain for certifying neural networks},
	volume = {3},
	year = {2019},
	Bdsk-Url-1 = {https://doi.org/10.1145/3290354}}

@article{JuRiKo20,
	author = {Julian, K. and Ritchie, L. and Kochenderfer, M.},
	journal = {CoRR},
	title = {Validation of Image-Based Neural Network Controllers through Adaptive Stress Testing},
	url = {http://arxiv.org/abs/2003.02381},
	volume = {abs/2003.02381},
	year = {2020},
	Bdsk-Url-1 = {http://arxiv.org/abs/2003.02381}}

@inproceedings{KaBaDiJuKo17Reluplex,
	author = {Guy Katz and Clark Barrett and David Dill and Kyle Ju-
lian and Mykel Kochenderfer},
	booktitle = {CAV},
	title = {{Reluplex: An Efficient SMT Solver for Verifying Deep Neural Networks}},
	year = {2017}}


@inproceedings{WaPeWhYaJa18,
	author = {Wang, S. and Pei, K. and Whitehouse, J. and Yang, J. and Jana, S.},
	booktitle = {Proc. 27th USENIX Security Symposium},
	title = {{Formal Security Analysis of Neural Networks using Symbolic Intervals}},
	year = {2018}}

@inproceedings{GeMiDrTsChVe18,
	author = {Timon Gehr and
               Matthew Mirman and
               Dana Drachsler{-}Cohen and
               Petar Tsankov and
               Swarat Chaudhuri and
               Martin T. Vechev},
	booktitle = {S\&P},
	title = {{AI2: Safety and Robustness Certification of Neural Networks with Abstract Interpretation}},
	year = {2018}}

@inproceedings{KKKAA20,
	author = {Wen Kokke and Ekaterina Komendantskaya and Daniel Kienitz and Bob Atkey and David Aspinall},
	booktitle = {APLAS},
	title = {Neural Networks, Secure by Construction: An Exploration of Refinement Types},
	year = {2020}}

@article{GuoJJZWJP20,
	author = {Zheng Guo and Michael James and David Justo and Jiaxiao Zhou and Ziteng Wang and Ranjit Jhala and Nadia Polikarpova},
	journal = {Proc. {ACM} Program. Lang.},
	number = {{POPL}},
	pages = {12:1--12:28},
	title = {Program synthesis by type-guided abstraction refinement},
	volume = {4},
	year = {2020}}

@article{KnothWRHP20,
	author = {Tristan Knoth and Di Wang and Adam Reynolds and Jan Hoffmann and Nadia Polikarpova},
	journal = {Proc. {ACM} Program. Lang.},
	number = {{ICFP}},
	pages = {106:1--106:29},
	title = {Liquid resource types},
	volume = {4},
	year = {2020}}

@inproceedings{BalunovicV20,
	author = {Mislav Balunovic and Martin T. Vechev},
	booktitle = {ICLR},
	title = {Adversarial Training and Provable Defenses: Bridging the Gap},
	year = {2020}}

@misc{KKK20-s,
	author = {Wen Kokke and Ekaterina Komendantskaya and Daniel Kienitz},
	title = {{StarChild}, a library for leveraging the refinement types and SMT solving of F* to verify properties of neural networks},
	url = {https://github.com/wenkokke/starchild},
	year = {2020},
	Bdsk-Url-1 = {https://github.com/wenkokke/starchild}}

@inproceedings{GoldbergerKAK20,
	author = {Ben Goldberger and Guy Katz and Yossi Adi and Joseph Keshet},
	booktitle = {LPAR},
	title = {Minimal Modifications of Deep Neural Networks using Verification},
	year = {2020}}

@misc{Ch20,
	author = {Chih-Hong Cheng},
	note = {FOMLAS'20, the 3rd Workshop on Formal Methods for ML-Enabled Autonomous Systems},
	title = {Research Challenges and Opportunities towards Safe Autonomous Driving. Invited talk.},
	year = {2020}}

@book{mcconnell,
	author = {Steve McConnell},
	title = {{Code Complete. A Practical Handbook of Software Construction, Second Edition}},
	year = 2015}

@article{fisher,
	author = {Kathleen Fisher and John Launchbury and Raymond Richards},
	journal = {Phil. Trans. R. Soc.},
	opttitle = {{HACMS program: using Formal Methods to Eliminate Exploitable Bugs}},
	title = {{Using Formal Methods to Eliminate Exploitable Bugs}},
	year = 2017}

@inproceedings{calcagno,
	author = {Cristiano Calcagno and Dino Distefano and J{\'{e}}r{\'{e}}my Dubreil and Dominik Gabi and Pieter Hooimeijer and Martino Luca and Peter W. O'Hearn and Irene Papakonstantinou and Jim Purbrick and Dulma Rodriguez},
	optbooktitle = {{NASA Formal Methods, LNCS 9058}},
	optpages = {3--11},
	title = {{Moving Fast with Software Verification}, In \emph{NASA Formal Methods}},
	year = 2015}

@article{slpj,
	author = {Simon Peyton Jones and Stephanie Weirich and Richard A. Eisenberg and Dimitrios Vytiniotis},
	title = {{A Reflection on Types --- A List of Successes That Can Change the World}},
	year = 2016}

@inproceedings{PapernotMSH16,
	author = {Nicolas Papernot and Patrick D. McDaniel and Ananthram Swami and Richard E. Harang},
	booktitle = {MILCOM},
	title = {Crafting adversarial input sequences for recurrent neural networks},
	year = {2016}}

@article{abs-1812-03303,
	author = {Stefanos Pertigkiozoglou and Petros Maragos},
	journal = {CoRR},
	title = {Detecting Adversarial Examples in Convolutional Neural Networks},
	url = {http://arxiv.org/abs/1812.03303},
	volume = {abs/1812.03303},
	year = {2018},
	Bdsk-Url-1 = {http://arxiv.org/abs/1812.03303}}

@article{SP18,
	author = {Alexandru Constantin Serban and Erik Poll},
	journal = {CoRR},
	title = {Adversarial Examples - {A} Complete Characterisation of the Phenomenon},
	url = {http://arxiv.org/abs/1810.01185},
	volume = {abs/1810.01185},
	year = {2018},
	Bdsk-Url-1 = {http://arxiv.org/abs/1810.01185}}

@article{PARISI201954,
	author = {G. Parisi and others},
	doi = {10.1016/j.neunet.2019.01.012},
	journal = {Neural Networks},
	pages = {54 - 71},
	title = {Continual lifelong learning with neural networks: A review},
	volume = {113},
	year = {2019},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.neunet.2019.01.012}}

@article{FLR17,
	author = {K.~Fisher and others},
	journal = {Phil. Trans. Royal Society},
	title = {The {HACMS} program: using formal methods to eliminate exploitable bugs},
	year = {2017}}

@inproceedings{swamy2016,
	author = {Nikhil Swamy and Markulf Kohlweiss and Jean-Karim Zinzindohoue and Santiago Zanella-B{\'{e}}guelin and C{\u{a}}t{\u{a}}lin Hri{\c{t}}cu and Chantal Keller and Aseem Rastogi and Antoine Delignat-Lavaud and Simon Forest and Karthikeyan Bhargavan and C{\'{e}}dric Fournet and Pierre-Yves Strub},
	booktitle = {Proceedings of the 43rd Annual {ACM} {SIGPLAN}-{SIGACT} Symposium on Principles of Programming Languages - {POPL} 2016},
	doi = {10.1145/2837614.2837655},
	publisher = {{ACM} Press},
	title = {Dependent types and multi-monadic effects in F*},
	year = {2016},
	Bdsk-Url-1 = {https://doi.org/10.1145/2837614.2837655}}

@phdthesis{vazou2016,
	author = {Niki Vazou},
	school = {University of California, San Diego, {USA}},
	title = {Liquid Haskell: Haskell as a Theorem Prover},
	year = {2016}}

@article{McP43,
	author = {W.S. McCulloch and W. Pitts},
	journal = {Bulletin of Math. Bio.},
	pages = {115-133},
	title = {A logical calculus of the ideas immanent in nervous activity},
	volume = {5},
	year = {1943}}

@inproceedings{barrett2010smt,
	author = {Barrett, Clark and Stump, Aaron and Tinelli, Cesare and others},
	booktitle = {Proceedings of the 8th international workshop on satisfiability modulo theories (Edinburgh, England)},
	pages = {14},
	title = {The smt-lib standard: Version 2.0},
	volume = {13},
	year = {2010}}

@misc{chollet2015keras,
	author = {Chollet, Fran\c{c}ois and others},
	howpublished = {{https://keras.io}},
	title = {Keras},
	year = {2015}}

@article{vazou2018,
	author = {Niki Vazou and Anish Tondwalkar and Vikraman Choudhury and Ryan G. Scott and Ryan R. Newton and Philip Wadler and Ranjit Jhala},
	doi = {10.1145/3158141},
	journal = {Proceedings of the {ACM} on Programming Languages},
	month = jan,
	number = {{POPL}},
	pages = {1--31},
	publisher = {Association for Computing Machinery ({ACM})},
	title = {Refinement reflection: complete verification with {SMT}},
	volume = {2},
	year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1145/3158141}}

@inproceedings{MouraB08,
	author = {Leonardo Mendon{\c{c}}a de Moura and Nikolaj Bj{\o}rner},
	booktitle = {TACAS'08},
	pages = {337--340},
	series = {LNCS},
	title = {{Z3:} An Efficient {SMT} Solver},
	volume = {4963},
	year = {2008}}

@incollection{Dutertre2006,
	author = {Bruno Dutertre and Leonardo de Moura},
	booktitle = {Computer Aided Verification},
	doi = {10.1007/11817963\_11},
	pages = {81--94},
	publisher = {Springer Berlin Heidelberg},
	title = {A Fast Linear-Arithmetic Solver for {DPLL}(T)},
	year = {2006},
	Bdsk-Url-1 = {https://doi.org/10.1007/11817963%5C_11}}

@article{Jovanovi2013,
	author = {Dejan Jovanovi{\'{c}} and Leonardo de Moura},
	doi = {10.1145/2429135.2429155},
	journal = {{ACM} Communications in Computer Algebra},
	month = jan,
	number = {3/4},
	pages = {104},
	publisher = {Association for Computing Machinery ({ACM})},
	title = {Solving non-linear arithmetic},
	volume = {46},
	year = {2013},
	Bdsk-Url-1 = {https://doi.org/10.1145/2429135.2429155}}

@article{Akbarpour2009,
	author = {Behzad Akbarpour and Lawrence Charles Paulson},
	doi = {10.1007/s10817-009-9149-2},
	journal = {Journal of Automated Reasoning},
	month = aug,
	number = {3},
	pages = {175--205},
	publisher = {Springer Science and Business Media {LLC}},
	title = {{MetiTarski}: An Automatic Theorem Prover for Real-Valued Special Functions},
	volume = {44},
	year = {2009},
	Bdsk-Url-1 = {https://doi.org/10.1007/s10817-009-9149-2}}

@article{BS19,
	author = {A. Bagnall and G. Stewart},
	journal = {AAAI},
	title = {Certifying True Error: Machine Learning in {Coq} with Verified Generalisation Guarantees},
	year = {2019}}

@inproceedings{WoodcockC00Y19,
	author = {Jim Woodcock and Ana Cavalcanti and Simon Foster and Alexandre Mota and Kangfeng Ye},
	booktitle = {{UTP} 2019},
	pages = {80--105},
	title = {{Probabilistic Semantics for RoboChart - {A} Weakest Completion Approach}},
	year = {2019}}

@inproceedings{Kwiatkowska19,
	author = {Marta Z. Kwiatkowska},
	booktitle = {{CONCUR} 2019,},
	editor = {Wan Fokkink and Rob van Glabbeek},
	pages = {1:1--1:5},
	publisher = {Schloss Dagstuhl - Leibniz-Zentrum f{\"{u}}r Informatik},
	series = {LIPIcs},
	title = {Safety Verification for Deep Neural Networks with Provable Guarantees (Invited Paper)},
	volume = {140},
	year = {2019}}

@inproceedings{DBLP:conf/fpga/UmurogluFGBLJV17,
	author = {Yaman Umuroglu and Nicholas J. Fraser and Giulio Gambardella and Michaela Blott and Philip Heng Wai Leong and Magnus Jahre and Kees A. Vissers},
	booktitle = {Proceedings of the 2017 {ACM/SIGDA} International Symposium on Field-Programmable Gate Arrays, {FPGA} 2017, Monterey, CA, USA, February 22-24, 2017},
	pages = {65--74},
	title = {{FINN:} {A} Framework for Fast, Scalable Binarized Neural Network Inference},
	year = {2017}}

@misc{tensorflow2015-whitepaper,
	author = {Mart\'{\i}n Abadi and Ashish Agarwal and Paul Barham and Eugene Brevdo and Zhifeng Chen and Craig Citro and Greg S. Corrado and Andy Davis and Jeffrey Dean and Matthieu Devin and Sanjay Ghemawat and Ian Goodfellow and Andrew Harp and Geoffrey Irving and Michael Isard and Yangqing Jia and Rafal Jozefowicz and Lukasz Kaiser and Manjunath Kudlur and Josh Levenberg and Dan Mane and Rajat Monga and Sherry Moore and Derek Murray and Chris Olah and Mike Schuster and Jonathon Shlens and Benoit Steiner and Ilya Sutskever and Kunal Talwar and Paul Tucker and Vincent Vanhoucke and Vijay Vasudevan and Fernanda Viegas and Oriol Vinyals and Pete Warden and Martin Wattenberg and Martin Wicke and Yuan Yu and Xiaoqiang Zheng},
	title = {{TensorFlow}: Large-Scale Machine Learning on Heterogeneous Distributed Systems},
	year = {2016}}

@inproceedings{batch_normalization_accelerating_deep_network_training_by_reducing_internal_covariate_shift_2015_ioffe,
	author = {Ioffe, Sergey and Szegedy, Christian},
	booktitle = {International conference on machine learning},
	organization = {PMLR},
	pages = {448--456},
	title = {Batch normalization: Accelerating deep network training by reducing internal covariate shift},
	year = {2015}}

@inproceedings{handwritten_digit_recognition_with_a_back_propagation_network_1990_lecun,
	author = {LeCun, Yann and Boser, Bernhard E and Denker, John S and Henderson, Donnie and Howard, Richard E and Hubbard, Wayne E and Jackel, Lawrence D},
	booktitle = {Advances in neural information processing systems},
	pages = {396--404},
	title = {Handwritten digit recognition with a back-propagation network},
	year = {1990}}

@techreport{learning_multiple_layers_of_features_from_tiny_images_2009_Krizhevsky,
	author = {Krizhevsky, Alex and Hinton, Geoffrey and others},
	institution = {Citeseer},
	title = {Learning multiple layers of features from tiny images},
	year = {2009}}

@book{Goodfellow-et-al-2016,
	author = {Ian Goodfellow and Yoshua Bengio and Aaron Courville},
	note = {\url{http://www.deeplearningbook.org}},
	publisher = {MIT Press},
	title = {Deep Learning},
	year = {2016}}

@inproceedings{tsipras2018robustness,
	author = {Tsipras, Dimitris and Santurkar, Shibani and Engstrom, Logan and Turner, Alexander and Madry, Aleksander},
	booktitle = {International Conference on Learning Representations},
	title = {Robustness May Be at Odds with Accuracy},
	year = {2018}}

@inproceedings{madry2018towards,
	author = {Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
	booktitle = {International Conference on Learning Representations},
	title = {Towards Deep Learning Models Resistant to Adversarial Attacks},
	year = {2018}}

@inproceedings{zhang2019theoretically,
	author = {Zhang, Hongyang and Yu, Yaodong and Jiao, Jiantao and Xing, Eric and El Ghaoui, Laurent and Jordan, Michael},
	booktitle = {International Conference on Machine Learning},
	organization = {PMLR},
	pages = {7472--7482},
	title = {Theoretically principled trade-off between robustness and accuracy},
	year = {2019}}

@inproceedings{bak2020improved,
	author = {Bak, Stanley and Tran, Hoang-Dung and Hobbs, Kerianne and Johnson, Taylor T},
	booktitle = {International Conference on Computer Aided Verification},
	organization = {Springer},
	pages = {66--96},
	title = {Improved geometric path enumeration for verifying {ReLU} neural networks},
	year = {2020}}

@article{pauli2021training,
	author = {Pauli, Patricia and Koch, Anne and Berberich, Julian and Kohler, Paul and Allgower, Frank},
	journal = {IEEE Control Systems Letters},
	publisher = {IEEE},
	title = {Training robust neural networks using {L}ipschitz bounds},
	year = {2021}}

@inproceedings{anil2019sorting,
	author = {Anil, Cem and Lucas, James and Grosse, Roger},
	booktitle = {International Conference on Machine Learning},
	organization = {PMLR},
	pages = {291--301},
	title = {Sorting out {L}ipschitz function approximation},
	year = {2019}}

@article{balan2018lipschitz,
	author = {Balan, Radu and Singh, Maneesh and Zou, Dongmian},
	journal = {Contemporary Mathematics},
	pages = {129--151},
	publisher = {American Mathematical Society},
	title = {Lipschitz properties for deep convolutional networks},
	volume = {706},
	year = {2018}}

@article{gouk2021regularisation,
	author = {Gouk, Henry and Frank, Eibe and Pfahringer, Bernhard and Cree, Michael J},
	journal = {Machine Learning},
	number = {2},
	pages = {393--416},
	publisher = {Springer},
	title = {Regularisation of neural networks by enforcing {L}ipschitz continuity},
	volume = {110},
	year = {2021}}

@article{raghunathan2019adversarial,
	author = {Raghunathan, Aditi and Xie, Sang Michael and Yang, Fanny and Duchi, John C and Liang, Percy},
	journal = {arXiv preprint arXiv:1906.06032},
	title = {Adversarial training can hurt generalization},
	year = {2019}}

@inproceedings{NIPS2012_c399862d,
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {F. Pereira and C. J. C. Burges and L. Bottou and K. Q. Weinberger},
	pages = {},
	publisher = {Curran Associates, Inc.},
	title = {ImageNet Classification with Deep Convolutional Neural Networks},
	url = {https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
	volume = {25},
	year = {2012}}

@inproceedings{lecun_optimal_1989,
	title = {Optimal {Brain} {Damage}},
	volume = {2},
	url = {https://papers.nips.cc/paper/1989/hash/6c9882bbac1c7093bd25041881277658-Abstract.html},
	abstract = {We  have used  information-theoretic ideas  to derive  a class of prac(cid:173) tical  and  nearly  optimal schemes  for  adapting the size  of a  neural  network.  By  removing  unimportant  weights  from  a  network,  sev(cid:173) eral  improvements  can  be  expected:  better  generalization,  fewer  training examples required,  and improved speed  of learning and/or  classification.  The  basic  idea  is  to  use  second-derivative  informa(cid:173) tion to make a  tradeoff between  network  complexity  and  training  set error.  Experiments confirm  the usefulness  of the methods on a  real-world  application.},
	urldate = {2022-05-11},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Morgan-Kaufmann},
	author = {LeCun, Yann and Denker, John and Solla, Sara},
	year = {1989},
	file = {Full Text PDF:/home/remi/Zotero/storage/EJADKETX/LeCun et al. - 1989 - Optimal Brain Damage.pdf:application/pdf},
}

@misc{noauthor_vnn_nodate,
	title = {{VNN} 2022},
	url = {https://sites.google.com/view/vnn2022},
	abstract = {News / Updates
February 23, 2022: website updated; please register tools for the competition in this Google form: https://forms.gle/RbGbKvfvn7bvTR1M9 
VNN-COMP'22 benchmarks and rules discussion: https://github.com/stanleybak/vnncomp2022/issues 
February 3, 2022: Much content is from last year's},
	language = {en-GB},
	urldate = {2022-05-16},
	journal = {VNN-Comp 2022},
	file = {Snapshot:/home/remi/Zotero/storage/2ZL8NQS3/vnn2022.html:text/html},
}

@inproceedings{dutta_output_2018,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Output {Range} {Analysis} for {Deep} {Feedforward} {Neural} {Networks}},
	isbn = {978-3-319-77935-5},
	doi = {10.1007/978-3-319-77935-5_9},
	abstract = {Given a neural network (NN) and a set of possible inputs to the network described by polyhedral constraints, we aim to compute a safe over-approximation of the set of possible output values. This operation is a fundamental primitive enabling the formal analysis of neural networks that are extensively used in a variety of machine learning tasks such as perception and control of autonomous systems. Increasingly, they are deployed in high-assurance applications, leading to a compelling use case for formal verification approaches. In this paper, we present an efficient range estimation algorithm that iterates between an expensive global combinatorial search using mixed-integer linear programming problems, and a relatively inexpensive local optimization that repeatedly seeks a local optimum of the function represented by the NN. We implement our approach and compare it with Reluplex, a recently proposed solver for deep neural networks. We demonstrate applications of our approach to computing flowpipes for neural network-based feedback controllers. We show that the use of local search in conjunction with mixed-integer linear programming solvers effectively reduces the combinatorial search over possible combinations of active neurons in the network by pruning away suboptimal nodes.},
	language = {en},
	booktitle = {{NASA} {Formal} {Methods}},
	publisher = {Springer International Publishing},
	author = {Dutta, Souradeep and Jha, Susmit and Sankaranarayanan, Sriram and Tiwari, Ashish},
	editor = {Dutle, Aaron and Muñoz, César and Narkawicz, Anthony},
	year = {2018},
	pages = {121--138},
	file = {Full Text PDF:/home/remi/Zotero/storage/SYYH7XX3/Dutta et al. - 2018 - Output Range Analysis for Deep Feedforward Neural .pdf:application/pdf},
}
